from jina import Document,DocumentArray

# d = Document(text = '_______________hello world____________')
# print(d.text)
#
# # d = Document(uri='https://www.baidu.com/')
# # d.load_uri_to_text()
# # print(d.text)
#
# d = Document(text='ğŸ‘‹	à¤¨à¤®à¤¸à¥à¤¤à¥‡ à¤¦à¥à¤¨à¤¿à¤¯à¤¾!	ä½ å¥½ä¸–ç•Œï¼ã“ã‚“ã«ã¡ã¯ä¸–ç•Œï¼	ĞŸÑ€Ğ¸Ğ²ĞµÑ‚ Ğ¼Ğ¸Ñ€!')
# print(d.text)
#
# d = Document(text='ğŸ‘‹	à¤¨à¤®à¤¸à¥à¤¤à¥‡ à¤¦à¥à¤¨à¤¿à¤¯à¤¾!	ä½ å¥½ä¸–ç•Œ! ã“ã‚“ã«ã¡ã¯ä¸–ç•Œ!	ĞŸÑ€Ğ¸Ğ²ĞµÑ‚ Ğ¼Ğ¸Ñ€!')
# d.chunks.extend([Document(text=c) for c in d.text.split('!')])  # æŒ‰'!'åˆ†å‰²,åˆ†å‰²ä½chunk
# d.summary()




# æœ€ç®€å•çš„æ–‡æœ¬å‘é‡ç¼–ç æ–¹å¼ï¼šå°†æ–‡æœ¬æŒ‰ç…§å•è¯å‡ºç°æ•°é‡è¿›è¡Œç¼–ç 
# da = DocumentArray([Document(text='hello world'),
#                     Document(text='goodbye world'),
#                     Document(text='hello goodbye')])
#
# vocab = da.get_vocabulary() # è¾“å‡º:{'hello':2, 'world':3, 'goodbye': 4}
#
#
# # è½¬ä¸ºndarray
# for d in da:
#     d.convert_text_to_tensor(vocab, max_length=10)
#     print(d.tensor)
#
#
# for d in da:
#     d.convert_tensor_to_text(vocab)
#     print(d.text)




# ç®€å•æ–‡æœ¬åŒ¹é…Demoï¼Œå»ºç«‹æ–‡æœ¬åº“å’Œå“ˆå¸Œç´¢å¼•
d = Document(uri='https://www.gutenberg.org/files/1342/1342-0.txt').load_uri_to_text() # è·å–æ–‡æœ¬
da = DocumentArray(Document(text= s.strip()) for s in d.text.split('\n') if s.strip()) # å°†æ–‡æœ¬åˆ‡åˆ†ä¸ºå¥å­
da.apply(lambda d: d.embed_feature_hashing()) # ä¸ºå¥å­å»ºç«‹å“ˆå¸Œç¼–ç 


# åŒ¹é…æ–‡æœ¬ç‰¹å¾ç¼–ç 
q = (
    Document(text='she entered the room') # è¦åŒ¹é…çš„æ–‡æœ¬
    .embed_feature_hashing()  # é€šè¿‡å“ˆå¸Œç¼–ç è¿›è¡ŒåŒ¹é…
    .match(da, limit=5, exclude_self=True, metric='jaccard', use_scipy=True) # æ‰¾åˆ°5ä¸ªæœ€ç›¸ä¼¼æ–‡æœ¬ï¼Œè¾“å‡ºä¸ºä¸jaccardç›¸ä¼¼ç¨‹åº¦
)


print(q.matches[:,('text','scores__jaccard')])



